{
    "collab_server" : "",
    "contents" : "---\ntitle: \"Trabalho Pr??tico 1 - Regras de Associa????o\"\noutput:\n  pdf_document: default\n  html_document: default\n---\n\n        Online Retail Market Basket Analysis\n        Semar Augusto da Cunha Mello Martins\t\n1 - Introdu????o:\n\t\n\tMarket Basket Analysis, is a tecnique used to identify products that tend to be bought together. Knowning that is powerful because the owner of the store will know which products should be placed close to each other.\n\t\n\tBesides that, its possible to know better which products should be placed in a big sale, because it makes more sense to put only one of the items in the basket in sale, since it will probably increase sales of the other items as well.\n\t\n\tDuring this project I used stock market data from 01/12/2010 to 09/12/2011. Analysing the rules created by the algorithm, we can answer the following question:\n* Can we predict the valuation of an stock given that another one, related to it, is valuing?\n\n\n```{r}\nlibrary(plyr)\nlibrary(tidyverse)\nlibrary(arules)\nlibrary(arulesViz)\n\nretail <- read_excel('Online retail.xlsx')\nretail <- retail[complete.cases(retail), ]\nretail <- retail %>% mutate(Description = as.factor(Description))\nretail <- retail %>% mutate(Country = as.factor(Country))\nretail$Date <- as.Date(retail$InvoiceDate)\nretail$Time <- format(retail$InvoiceDate,\"%H:%M:%S\")\nretail$InvoiceNo <- as.numeric(as.character(retail$InvoiceNo))\n```\n\n```{r}\nglimpse(retail)\nstr(retail)\n```\n\nAfter preprocessing, the dataset includes 406,829 records and 10 fields: InvoiceNo, StockCode, Description, Quantity, InvoiceDate, UnitPrice, CustomerID, Country, Date, Time.\n\n### What time do people often purchase online?\n\nIn order to find the answer to this question, we need to extract \"hour\" from the time column.\n\n```{r}\nretail$Time <- as.factor(retail$Time)\na <- hms(as.character(retail$Time))\nretail$Time = hour(a)\n\nretail %>% \n  ggplot(aes(x=Time)) + \n  geom_histogram(stat=\"count\",fill=\"indianred\")\n```\n\nThere is a clear effect of hour of day on order volume. Most orders happened between 11:00-15:00.\n\n### How many items each customer buy?\n\nPeople mostly purchase less than 10 items (less than 10 items in each invoice). Those negative numbers should be returns. \n\n```{r}\ndetach(\"package:plyr\", unload=TRUE) \n\nretail %>% \n  group_by(InvoiceNo) %>% \n  summarize(n_items = mean(Quantity)) %>%\n  ggplot(aes(x=n_items))+\n  geom_histogram(fill=\"steelblue3\", bins = 100000) + \n  geom_rug() +\n  coord_cartesian(xlim=c(0,80))\n```\n\n### Top 10 best sellers\n\n```{r}\ntmp <- retail %>% \n  group_by(StockCode, Description) %>% \n  summarize(count = n()) %>% \n  arrange(desc(count))\ntmp <- head(tmp, n=10)\ntmp\n\ntmp %>% \n  ggplot(aes(x=reorder(Description,count), y=count))+\n  geom_bar(stat=\"identity\",fill=\"indian red\")+\n  coord_flip()\n```\n\n## Association rules for online retailer\n\nBefore using any rule mining algorithm, we need to transform data from the data frame format into transactions such that we have all the items bought together in one row. For example, this is the format we need:\n\n```{r}\nretail_sorted <- retail[order(retail$CustomerID),]\nlibrary(plyr)\nitemList <- ddply(retail,c(\"InvoiceNo\"), \n                       function(df1)paste(df1$Description, \n                       collapse = \",\"))\n```\n\nThe function ddply() accepts a data frame, splits it into pieces based on one or more factors, computes on the pieces, then returns the results as a data frame. We use \",\" to separate different items. \n\nWe only need item transactions, so, remove customerID and Date columns.\n\n```{r}\nitemList$CustomerID <- NULL\nitemList$Date <- NULL\ncolnames(itemList) <- c(\"items\")\n```\n\nWrite the data from to a csv file and check whether our transaction format is correct. \n\n```{r}\nwrite.csv(itemList,\"market_basket.csv\", quote = FALSE, row.names = TRUE)\n```\n\nPerfect! Now we have our transaction dataset shows the matrix of items being bought together. We don't actually see how often they are bought together, we don't see rules either. But we are going to find out. \n\nLet's have a closer look how many transaction we have and what they are.\n\n```{r}\nprint('Description of the transactions')\ntr <- read.transactions('market_basket.csv', format = 'basket', sep=',')\ntr\nsummary(tr)\n```\n\nWe see 19,296 transactions, this is the number of rows as well, and 7,881 items, remember items are the product descriptions in our original dataset. Transaction here is the collections or subsets of these 7,881 items. \n\nThe summary gives us some useful information:\n\n* density: The percentage of non-empty cells in the sparse matrix. In another word, the total number of items that purchased divided by the total number of possible items in that matrix. We can calculate how many items were purchased using density like so: \n\n19296 X 7881 X 0.0022\n\n* The most frequent items should be same with our results in Figure 3.\n\n* For the sizes of the transactions, 2247 transactions for just 1 items, 1147 transactions for 2 items, all the way up to the biggest transaction: 1 transaction for 420 items. This indicates that most customers buy small number of items on each purchase.\n\n* The data distribution is right skewed.\n\nLet's have a look item freqnency plot, this should be in align with Figure 3.\n\n```{r}\nitemFrequencyPlot(tr, topN=20, type='absolute')\n```\n\n```{r}\nitemsets <- apriori(tr,\n                    parameter = list(support=.001,\n                                     minlen=2,\n                                     target='frequent' # to mine for itemsets\n                                     ))\n```\n\n```{r}\nsummary(itemsets)\n```\n\n```{r}\ninspect(sort(itemsets, by='support', decreasing = T)[1:5])\ninspect(sort(itemsets, by='support', decreasing = F)[1:5])\n```\n\n```{r}\nquality(itemsets)$lift <- interestMeasure(itemsets, measure='lift', tr)\ninspect(sort(itemsets, by ='lift', decreasing = T)[1:5])\ninspect(sort(itemsets, by ='lift', dddddecreasing = F)[1:5])\n```\n\n\n## Create some rules\n\n* We use the Apriori algorithm in arules library to mine frequent itemsets and association rules. The algorithm employs level-wise search for frequent itemsets.\n\n* We pass supp=0.001 and conf=0.8 to return all the rules have a support of at least 0.1% and confidence of at least 80%. \n\n* We sort the rules by decreasing confidence. \n\n* Have a look the summary of the rules. \n\n```{r}\nrules <- apriori(tr, parameter = list(supp=0.005, conf=0.9))\nrules <- sort(rules, by='confidence', decreasing = TRUE)\nsummary(rules)\n```\n\n* The number of rules: 89,697.\n* The distribution of rules by length: Most rules are 6 items long.\n* The summary of quality measures: ranges of support, confidence, and lift.\n* The information on the data mining: total data mined, and minimum parameters we set earlier.\n\nWe have 89,697 rules, I don't want to print them all, let's inspect top 10.\n\n```{r}\ninspect(rules[1:10])\n```\n\n* 100% customers who bought \"WOBBLY CHICKEN\" end up bought \"DECORATION\" as well. \n\n* 100% customers who bought \"BLACK TEA\" end up bought \"SUGAR JAR\" as well. \n\nAnd plot these top 10 rules.\n\n```{r}\nbestRules <- rules[1:10]\nplot(bestRules)\ninspect(rules[1:10])\n```\n\n```{r}\nplot(bestRules, method=\"graph\")\n```\n\n\nresumir as regras pra ficar f??cil de entneder.\n\n```{r}\nretail <- retail %>%\n    mutate(Description = fct_recode(Description,\n                                    \"HERB MARKER\" = \"HERB MARKER ROSEMARY\",\n                                    \"HERB MARKER\" = \"HERB MARKER BASIL\",\n                                    \"HERB MARKER\" = \"HERB MARKER CHIVES\",\n                                    \"HERB MARKER\" = \"HERB MARKER PARSLEY\",\n                                    \"HERB MARKER\" = \"HERB MARKER THYME\",\n                                    \"HERB MARKER\" = \"HERB MARKER MINT\"))\n```\n\n",
    "created" : 1509551248716.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "754828818",
    "id" : "2A8A1888",
    "lastKnownWriteTime" : 1533254374,
    "last_content_update" : 1533254374,
    "path" : "~/Desktop/Faculdade/MineracaoDados/TP1/Data-Analysis-with-R/TP1.Rmd",
    "project_path" : "Data-Analysis-with-R/TP1.Rmd",
    "properties" : {
        "marks" : "<:0,0\n>:0,0"
    },
    "relative_order" : 4,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_markdown"
}